{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae52825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (50000, 3)\n",
      "\n",
      "Class distribution:\n",
      "relation\n",
      "Support    25000\n",
      "Attack     25000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>parent_clean</th>\n",
       "      <th>child_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support</td>\n",
       "      <td>minors can be allowed to socially transition ,...</td>\n",
       "      <td>the vast majority of minors who socially trans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support</td>\n",
       "      <td>the us government also has an obligation to fu...</td>\n",
       "      <td>governments should be responsive to the intere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support</td>\n",
       "      <td>being non violent does not imply being better....</td>\n",
       "      <td>violence can be the determining factor between...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attack</td>\n",
       "      <td>multinational corporations benefit workers in ...</td>\n",
       "      <td>in china, apple pays its factory workers 3.15 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support</td>\n",
       "      <td>political division in america has increased ov...</td>\n",
       "      <td>the causes of this division are multi faceted ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relation                                       parent_clean  \\\n",
       "0  Support  minors can be allowed to socially transition ,...   \n",
       "1  Support  the us government also has an obligation to fu...   \n",
       "2  Support  being non violent does not imply being better....   \n",
       "3   Attack  multinational corporations benefit workers in ...   \n",
       "4  Support  political division in america has increased ov...   \n",
       "\n",
       "                                         child_clean  label  \n",
       "0  the vast majority of minors who socially trans...      1  \n",
       "1  governments should be responsive to the intere...      1  \n",
       "2  violence can be the determining factor between...      1  \n",
       "3  in china, apple pays its factory workers 3.15 ...      0  \n",
       "4  the causes of this division are multi faceted ...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../../data/kialo/kialo-pairs-50k.csv')\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'\\nClass distribution:\\n{df[\"relation\"].value_counts()}')\n",
    "\n",
    "# Encode labels\n",
    "label_map = {'Support': 1, 'Attack': 0}\n",
    "df['label'] = df['relation'].map(label_map)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e6bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 40000\n",
      "Val size: 5000\n",
      "Test size: 5000\n"
     ]
    }
   ],
   "source": [
    "# Train-test split with larger training set\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f'\\nTrain size: {len(train_df)}')\n",
    "print(f'Val size: {len(val_df)}')\n",
    "print(f'Test size: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5394c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class with improved tokenization\n",
    "class ArgumentPairDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        parent = str(self.data.loc[idx, 'parent_clean'])\n",
    "        child = str(self.data.loc[idx, 'child_clean'])\n",
    "        label = self.data.loc[idx, 'label']\n",
    "        \n",
    "        # Tokenize with clear separation and special prompt\n",
    "        encoding = self.tokenizer(\n",
    "            parent,\n",
    "            child,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation='only_second',  # Prioritize keeping parent complete\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f492c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training steps: 15000\n",
      "Warmup steps: 1500\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta-base'\n",
    "print(f'\\nUsing model: {model_name}')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    # hidden_dropout_prob=0.1,\n",
    "    # attention_probs_dropout_prob=0.1,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8  # Small batch for better gradients\n",
    "max_length = 256  # Long enough to capture full arguments\n",
    "learning_rate = 2e-5\n",
    "epochs = 3\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ArgumentPairDataset(train_df, tokenizer, max_length)\n",
    "val_dataset = ArgumentPairDataset(val_df, tokenizer, max_length)\n",
    "test_dataset = ArgumentPairDataset(test_df, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    eps=1e-8,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f'\\nTotal training steps: {total_steps}')\n",
    "print(f'Warmup steps: {warmup_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f18590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with gradient accumulation\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device, accumulation_steps=2):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    \n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss / accumulation_steps  # Scale loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        \n",
    "        logits = outputs.logits.detach()\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss.item() * accumulation_steps,\n",
    "            'lr': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    \n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    \n",
    "    return avg_loss, acc, f1, predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d27f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting training...\n",
      "============================================================\n",
      "\n",
      "Epoch 1/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5000/5000 [13:59<00:00,  5.96it/s, loss=0.305, lr=1.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5264 | Acc: 0.7257 | F1: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:31<00:00, 20.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4455 | Acc: 0.7974 | F1: 0.7974\n",
      "✓ Saved new best model (F1: 0.7974)\n",
      "\n",
      "Epoch 2/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5000/5000 [14:28<00:00,  5.76it/s, loss=0.126, lr=1.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3880 | Acc: 0.8304 | F1: 0.8303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:33<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4586 | Acc: 0.8086 | F1: 0.8083\n",
      "✓ Saved new best model (F1: 0.8083)\n",
      "\n",
      "Epoch 3/3\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5000/5000 [14:37<00:00,  5.70it/s, loss=0.343, lr=1.11e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2819 | Acc: 0.8887 | F1: 0.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:34<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4831 | Acc: 0.8094 | F1: 0.8092\n",
      "✓ Saved new best model (F1: 0.8092)\n",
      "\n",
      "============================================================\n",
      "Evaluating on test set with best model...\n",
      "============================================================\n",
      "Loaded model from epoch 3 with val F1: 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [00:33<00:00, 18.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack     0.8328    0.7948    0.8133      2500\n",
      "     Support     0.8037    0.8404    0.8217      2500\n",
      "\n",
      "    accuracy                         0.8176      5000\n",
      "   macro avg     0.8183    0.8176    0.8175      5000\n",
      "weighted avg     0.8183    0.8176    0.8175      5000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1987  513]\n",
      " [ 399 2101]]\n",
      "\n",
      "Test Loss: 0.4658\n",
      "Test F1 Score: 0.8175\n",
      "Test Accuracy: 0.8176\n",
      "\n",
      "Per-class accuracy:\n",
      "Attack: 0.7948\n",
      "Support: 0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop with early stopping\n",
    "best_val_f1 = 0\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Starting training...')\n",
    "print('='*60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    train_loss, train_acc, train_f1 = train_epoch(\n",
    "        model, train_loader, optimizer, scheduler, device\n",
    "    )\n",
    "    print(f'Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')\n",
    "    \n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "    print(f'Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_f1': val_f1,\n",
    "        }, 'best_bert_model.pt')\n",
    "        print(f'✓ Saved new best model (F1: {val_f1:.4f})')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "            break\n",
    "\n",
    "\n",
    "# Load best model and evaluate on test set\n",
    "print('\\n' + '='*60)\n",
    "print('Evaluating on test set with best model...')\n",
    "print('='*60)\n",
    "\n",
    "checkpoint = torch.load('best_bert_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch'] + 1} with val F1: {checkpoint['val_f1']:.4f}\")\n",
    "\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "# Detailed classification report\n",
    "label_names = ['Attack', 'Support']\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(test_labels, test_preds, target_names=label_names, digits=4))\n",
    "\n",
    "print('\\nConfusion Matrix:')\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(cm)\n",
    "\n",
    "print(f'\\nTest Loss: {test_loss:.4f}')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nPer-class accuracy:')\n",
    "print(f'Attack: {cm[0,0]/(cm[0,0]+cm[0,1]):.4f}')\n",
    "print(f'Support: {cm[1,1]/(cm[1,0]+cm[1,1]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779e7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/bert-argument/tokenizer_config.json',\n",
       " './models/bert-argument/special_tokens_map.json',\n",
       " './models/bert-argument/vocab.json',\n",
       " './models/bert-argument/merges.txt',\n",
       " './models/bert-argument/added_tokens.json',\n",
       " './models/bert-argument/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"../../models/bert-argument\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbca1196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Example Predictions:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Parent: identifying hate crime is inherently based on imprecise assumptions....\n",
      "Child: there is no way to tell a perpetrator's true motivation....\n",
      "True: Support | Predicted: Support (conf: 0.963)\n",
      "✓\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Parent: the potential nutritional challenges associated with a vegetarian diet can be ef...\n",
      "Child: the need of supplements is specially important among vegans, however, lacto ovo ...\n",
      "True: Attack | Predicted: Support (conf: 0.940)\n",
      "✗\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Parent: a tiktok ban might fail to address concerns about access to user data....\n",
      "Child: the ban on tiktok might redirect users to alternative platforms that have simila...\n",
      "True: Support | Predicted: Support (conf: 0.992)\n",
      "✓\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Parent: the process of closing a zoo is progressive. in these cases, animals unable to s...\n",
      "Child: because she is a hybrid of two orangutan sub species she wouldn't socialise if r...\n",
      "True: Support | Predicted: Attack (conf: 0.947)\n",
      "✗\n",
      "------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Parent: societies that consume unsustainably are, by definition, more likely to collapse...\n",
      "Child: selection via natural causes of societal collapse is a form of natural selection...\n",
      "True: Attack | Predicted: Attack (conf: 0.995)\n",
      "✓\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Training completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Inference function\n",
    "def predict_relation(parent_text, child_text, model, tokenizer, device, max_length=256):\n",
    "    \"\"\"Predict relation between two arguments\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        parent_text,\n",
    "        child_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation='only_second',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    relation = 'Support' if pred == 1 else 'Attack'\n",
    "    confidence = probs[0][pred].item()\n",
    "    \n",
    "    return relation, confidence\n",
    "\n",
    "\n",
    "# Example predictions\n",
    "print('\\n' + '='*60)\n",
    "print('Example Predictions:')\n",
    "print('='*60)\n",
    "\n",
    "examples = test_df.sample(5).reset_index(drop=True)\n",
    "for i in range(len(examples)):\n",
    "    parent = examples.loc[i, 'parent_clean']\n",
    "    child = examples.loc[i, 'child_clean']\n",
    "    true_label = examples.loc[i, 'relation']\n",
    "    \n",
    "    pred_relation, confidence = predict_relation(parent, child, model, tokenizer, device)\n",
    "    \n",
    "    print(f'\\nExample {i+1}:')\n",
    "    print(f'Parent: {parent[:80]}...')\n",
    "    print(f'Child: {child[:80]}...')\n",
    "    print(f'True: {true_label} | Predicted: {pred_relation} (conf: {confidence:.3f})')\n",
    "    match = '✓' if pred_relation == true_label else '✗'\n",
    "    print(f'{match}')\n",
    "    print('-' * 60)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Training completed!')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
